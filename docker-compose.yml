version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: talks-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # Ollama Model Initialization
  ollama-init:
    image: curlimages/curl:latest
    container_name: talks-ollama-init

    depends_on:
      ollama:
        condition: service_started

    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        echo 'Ollama is healthy, starting model initialization...'
        sleep 5

        # Function to pull and verify a model
        pull_model() {
          MODEL_NAME="$$1"
          echo "Checking if model $$MODEL_NAME exists..."

          if ! curl -s --max-time 10 http://ollama:11434/api/tags | grep -q "$$MODEL_NAME"; then
            echo "Model $$MODEL_NAME not found. Pulling..."

            # Pull the model
            curl -X POST http://ollama:11434/api/pull \
              -H 'Content-Type: application/json' \
              -d "{\"name\": \"$$MODEL_NAME\"}" \
              --max-time 7200

            if [ $$? -eq 0 ]; then
              echo "Model $$MODEL_NAME pull completed"

              # Wait for model to be available
              for i in {1..30}; do
                if curl -s http://ollama:11434/api/tags | grep -q "$$MODEL_NAME"; then
                  echo "Model $$MODEL_NAME successfully loaded"

                  # Test the model
                  echo "Testing model $$MODEL_NAME..."
                  if curl -X POST http://ollama:11434/api/generate \
                    -H 'Content-Type: application/json' \
                    -d "{\"model\": \"$$MODEL_NAME\", \"prompt\": \"Hello\", \"stream\": false}" \
                    --max-time 120 | grep -q '"response"'; then
                    echo "Model $$MODEL_NAME test successful!"
                  else
                    echo "Model $$MODEL_NAME test failed"
                  fi
                  break
                fi
                echo "Waiting for model $$MODEL_NAME... attempt $$i/30"
                sleep 10
              done
            else
              echo "Model $$MODEL_NAME pull failed"
              return 1
            fi
          else
            echo "Model $$MODEL_NAME already exists"

            # Test existing model
            echo "Testing existing model $$MODEL_NAME..."
            if curl -X POST http://ollama:11434/api/generate \
              -H 'Content-Type: application/json' \
              -d "{\"model\": \"$$MODEL_NAME\", \"prompt\": \"Hi\", \"stream\": false}" \
              --max-time 120 | grep -q '"response"'; then
              echo "Model $$MODEL_NAME test successful!"
            else
              echo "Model $$MODEL_NAME exists but test failed"
            fi
          fi
        }

        # Pull all required models
        echo "Starting model pulls..."
        pull_model "qwen3:32b"

        echo "All models initialization complete!"
    restart: "no"


  chromadb:
    image: chromadb/chroma:latest
    container_name: talks-chromadb
    ports:
      - "8000:8000"
    volumes:
      - chromadb_data:/chroma/chroma
    environment:
      - IS_PERSISTENT=TRUE
      - ANONYMIZED_TELEMETRY=FALSE
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: talks-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    restart: unless-stopped

volumes:
  ollama_data:
  chromadb_data:
  redis_data: