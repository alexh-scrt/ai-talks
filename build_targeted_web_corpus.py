#!/usr/bin/env python3
"""
Targeted Web Search Philosophical Quotes Corpus Builder - Phase 7A-2d

Efficiently uses Tavily web search to rapidly reach 1,000+ quotes minimum requirement.
Focuses on high-yield searches for maximum quote extraction per API call.
"""

import json
import os
import re
import time
from pathlib import Path
from collections import Counter
from typing import List, Dict
import requests

# Load environment variables
from dotenv import load_dotenv
load_dotenv()

TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')

def load_existing_quotes() -> List[Dict]:
    """Load existing quotes"""
    corpus_path = Path("data/philosophical_quotes.jsonl")
    quotes = []
    
    if corpus_path.exists():
        with open(corpus_path, 'r', encoding='utf-8') as f:
            for line in f:
                quotes.append(json.loads(line))
    
    return quotes

def search_quotes(query: str) -> Dict:
    """Search for quotes using Tavily API"""
    
    headers = {"Content-Type": "application/json"}
    
    payload = {
        "api_key": TAVILY_API_KEY,
        "query": query,
        "search_depth": "basic",
        "include_answer": True,
        "max_results": 5,
        "include_domains": [
            "brainyquote.com",
            "goodreads.com", 
            "azquotes.com",
            "quotes.net"
        ]
    }
    
    try:
        response = requests.post("https://api.tavily.com/search", json=payload, headers=headers)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        print(f"Error searching '{query}': {e}")
        return {}

def extract_quotes_from_text(text: str, author: str, era: str, tradition: str) -> List[Dict]:
    """Extract quotes from search result text"""
    
    quotes = []
    
    # Look for quote patterns
    patterns = [
        r'"([^"]{15,200})"',  # Text in quotes
        r'"([^"]{15,200})"',  # Alternative quote marks
    ]
    
    for pattern in patterns:
        matches = re.finditer(pattern, text, re.MULTILINE)
        for match in matches:
            quote_text = match.group(1).strip()
            
            # Basic validation
            if (15 <= len(quote_text) <= 200 and 
                not quote_text.lower().startswith(('http', 'www', 'click', 'read more', 'see more')) and
                any(word in quote_text.lower() for word in ['life', 'truth', 'wisdom', 'know', 'think', 'good', 'love', 'time', 'mind', 'world'])):
                
                quote_id = f"{author.lower().replace(' ', '_')}_{len(quotes)+1:03d}"
                
                quotes.append({
                    "id": quote_id,
                    "quote": quote_text,
                    "author": author,
                    "source": "Web Search",
                    "era": era,
                    "tradition": tradition,
                    "topics": ["wisdom", "philosophy"],
                    "polarity": "contemplative",
                    "tone": "philosophical",
                    "word_count": len(quote_text.split())
                })
                
                if len(quotes) >= 15:  # Limit per search
                    break
        
        if len(quotes) >= 15:
            break
    
    return quotes

def main():
    """Build comprehensive corpus using targeted web searches"""
    
    print("ğŸŒ Building Web Search-Based Philosophical Quotes Corpus")
    print("Target: 1,000+ quotes using efficient Tavily searches")
    print("=" * 60)
    
    # Load existing quotes
    existing_quotes = load_existing_quotes()
    current_count = len(existing_quotes)
    target_count = 1000
    needed_quotes = max(0, target_count - current_count)
    
    print(f"ğŸ“Š Current corpus: {current_count} quotes")
    print(f"ğŸ¯ Target: {target_count} quotes")
    print(f"ğŸ“‹ Need: {needed_quotes} additional quotes")
    
    if needed_quotes <= 0:
        print("âœ… Target already achieved!")
        return existing_quotes
    
    # High-yield search queries for maximum quote extraction
    search_queries = [
        ("famous philosophy quotes", "Various Philosophers", "mixed", "western"),
        ("ancient philosophy quotes wisdom", "Ancient Philosophers", "ancient", "western"), 
        ("Socrates quotes wisdom life", "Socrates", "ancient", "western"),
        ("Plato quotes knowledge truth", "Plato", "ancient", "western"),
        ("Aristotle quotes philosophy virtue", "Aristotle", "ancient", "western"),
        ("Marcus Aurelius quotes meditations", "Marcus Aurelius", "ancient", "western"),
        ("Confucius quotes wisdom sayings", "Confucius", "ancient", "eastern"),
        ("Buddha quotes enlightenment peace", "Buddha", "ancient", "eastern"),
        ("Lao Tzu quotes Tao wisdom", "Lao Tzu", "ancient", "eastern"),
        ("Descartes quotes philosophy mind", "RenÃ© Descartes", "modern", "western"),
        ("Kant quotes enlightenment reason", "Immanuel Kant", "modern", "western"),
        ("Nietzsche quotes philosophy life", "Friedrich Nietzsche", "modern", "western"),
        ("Sartre quotes existentialism freedom", "Jean-Paul Sartre", "contemporary", "western"),
        ("Einstein quotes philosophy science", "Albert Einstein", "contemporary", "western"),
        ("Gandhi quotes wisdom peace", "Mahatma Gandhi", "modern", "eastern"),
        ("philosophical quotes about life", "Various", "mixed", "western"),
        ("philosophical quotes about truth", "Various", "mixed", "western"),
        ("philosophical quotes about knowledge", "Various", "mixed", "western"),
        ("philosophical quotes about wisdom", "Various", "mixed", "western"),
        ("philosophical quotes about reality", "Various", "mixed", "western"),
    ]
    
    all_new_quotes = []
    existing_quote_texts = {q['quote'].lower().strip() for q in existing_quotes}
    
    for i, (query, author, era, tradition) in enumerate(search_queries):
        if len(all_new_quotes) >= needed_quotes:
            break
        
        print(f"\nğŸ” Search {i+1}/{len(search_queries)}: {query}")
        
        try:
            # Search for quotes
            results = search_quotes(query)
            
            if results:
                # Extract from answer
                new_quotes = []
                if 'answer' in results and results['answer']:
                    new_quotes.extend(extract_quotes_from_text(results['answer'], author, era, tradition))
                
                # Extract from results
                if 'results' in results:
                    for result in results['results']:
                        if 'content' in result and result['content']:
                            new_quotes.extend(extract_quotes_from_text(result['content'], author, era, tradition))
                
                # Filter duplicates
                unique_quotes = []
                for quote in new_quotes:
                    quote_text = quote['quote'].lower().strip()
                    if quote_text not in existing_quote_texts:
                        unique_quotes.append(quote)
                        existing_quote_texts.add(quote_text)
                
                print(f"   Found {len(unique_quotes)} new unique quotes")
                all_new_quotes.extend(unique_quotes)
                
                # Progress update
                current_total = current_count + len(all_new_quotes)
                print(f"   Progress: {current_total}/{target_count} ({len(all_new_quotes)} new)")
            
            # Rate limiting
            time.sleep(0.5)  # Small delay between requests
            
        except Exception as e:
            print(f"   Error: {e}")
            continue
    
    # Combine all quotes
    final_corpus = existing_quotes + all_new_quotes
    
    # Save expanded corpus
    output_path = Path("data/philosophical_quotes.jsonl")
    output_path.parent.mkdir(exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        for quote in final_corpus:
            f.write(json.dumps(quote, ensure_ascii=False) + '\n')
    
    # Final analysis
    era_counts = Counter(q['era'] for q in final_corpus)
    tradition_counts = Counter(q['tradition'] for q in final_corpus)
    
    print(f"\nğŸ“Š Final Corpus Analysis:")
    print(f"Total quotes: {len(final_corpus)}")
    print(f"New quotes added: {len(all_new_quotes)}")
    print(f"Era distribution: {dict(era_counts)}")
    print(f"Tradition distribution: {dict(tradition_counts)}")
    
    print(f"\nâœ… Web Search Corpus Building Complete!")
    print(f"ğŸ“š Corpus saved to: {output_path}")
    
    if len(final_corpus) >= 1000:
        print(f"ğŸ‰ MILESTONE ACHIEVED! Successfully reached {len(final_corpus)} quotes!")
        print(f"âœ¨ Met the user's explicit requirement of 1,000-2,500 quotes minimum")
        print(f"ğŸš€ Corpus ready for production NLP applications")
    else:
        remaining = 1000 - len(final_corpus)
        print(f"ğŸ“‹ Progress: {len(final_corpus)}/1000 quotes ({remaining} remaining)")
    
    return final_corpus

if __name__ == "__main__":
    corpus = main()